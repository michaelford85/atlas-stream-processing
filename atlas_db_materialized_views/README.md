# MongoDB Atlas Materialized Views Demo

This folder contains the configuration and Stream Processor templates used to create **materialized views** in MongoDB Atlas Stream Processing, based on the built-in **Sample Analytics dataset**.

The pipeline demonstrates how to progressively enrich transactional data from multiple collections (customers, accounts, and transactions) into a final view called `transactions_enriched`.

---

## ğŸ”§ Overview

This demo provisions four Atlas Stream Processors using the templates in this folder:

| Processor | Source | Output | Description |
|------------|---------|---------|--------------|
| `customers_ref` | `sample_analytics.customers` | `sample_analytics.customers_ref` | Normalizes customer records and selects key fields. |
| `accounts_ref` | `sample_analytics.accounts` | `sample_analytics.accounts_ref` | Normalizes account records and exposes product and limit details. |
| `transactions_flat` | `sample_analytics.transactions` | `sample_analytics.transactions_flat` | Flattens nested transaction data and prepares it for enrichment. |
| `transactions_enriched` | `transactions_flat` + lookups | `sample_analytics.transactions_enriched` | Joins transactions with customer and account data, adds tier details and product lists. |

---

## ğŸ§© Data Flow

```
customers_ref -â”€--â”
                  â”‚
accounts_ref  â”€--â”€â”¼â”€â”€â–¶ transactions_enriched
                  â”‚
transactions_flat â”˜
```

Each stage reads from MongoDB sample data collections and writes its output back into the same Atlas cluster (`sample_analytics` database). The result is a progressively enriched materialized view.

---

## ğŸ“ File Structure

```
atlas_materialized_views/
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ customers_ref.j2
â”‚   â”œâ”€â”€ accounts_ref.j2
â”‚   â”œâ”€â”€ transactions_flat.j2
â”‚   â””â”€â”€ transactions_enriched.j2            â† updated to join customers_ref + accounts_ref
â”œâ”€â”€ processor_details.yml                   â† public-safe config (no credentials)
â”œâ”€â”€ processor_details_local.yml             â† local config (private keys, workspace info)
â”œâ”€â”€ create-sink-colls-indexes.yml           â† Ensures the existence of the materialized view collections and required indexes 
â”œâ”€â”€ create-asp-source-sink-connections.yml  â† creates Atlas Stream Processing connections
â”œâ”€â”€ backfill-analytics-views.yml            â† populates `accounts_ref`, `customers_ref`, and `transactions_enriched` collections with existing sample data
â””â”€â”€ deploy-analytics-views.yml              â† deploys stream processors for future transaction data
```

---

## ğŸš€ Running the Demo

### 1. Prerequisites

- MongoDB Atlas account (Free Tier is fine)
- Access to the **Sample Datasets** (enable in your Atlas cluster under *Collections â†’ Load Sample Dataset*)
- Atlas Programmatic API Keys (use your own keys for local use)
- Ansible and Python 3 installed locally

### 2. Configure the Environment

Copy the local configuration template and fill in your Atlas details:

```bash
cp processor_details.yml processor_details_local.yml
```

Then edit `processor_details_local.yml` with your:
- `atlas_group_id` (your Atlas Project ID)
- `atlas_public_key` / `atlas_private_key`
- `atlas_cluster_name` and `atlas_cluster_uri`

### 3. Deploy the Stream Processors

Run the Ansible playbook to create all processors in your Atlas environment:

```bash
ansible-playbook create_processors.yml -e @processor_details_local.yml
```

This will automatically register and start:
- `customers_ref`
- `accounts_ref`
- `transactions_flat`
- `transactions_enriched`

Each processor runs continuously, maintaining up-to-date materialized views.

---

## ğŸ§  What the Enriched View Includes

The final `transactions_enriched` collection combines multiple dimensions:

- **Customer Information**: username, name, email, tier_and_details
- **Account Details**: product list, limit values
- **Transaction Metrics**: amount, price, transaction code, date, symbol
- **Derived Tier Detail**: extracted per-account tier from `tier_and_details`

Example document:

```json
{
  "account_id": 443178,
  "date": "2016-06-14T00:00:00Z",
  "symbol": "team",
  "amount": 9240,
  "price": "24.15",
  "transaction_code": "buy",
  "customer_username": "fmmiller",
  "customer_name": "Elizabeth Ray",
  "customer_email": "arroyocolton@gmail.com",
  "tier_detail": {
    "tier": "Platinum",
    "discount": 0.05
  },
  "products": [
    { "type": "Credit Card", "name": "Rewards Plus" },
    { "type": "Loan", "name": "Auto Advantage" }
  ]
}
```

---

## ğŸ§° Customizing

You can safely edit the `.j2` templates to:
- Change database or collection names.
- Add new derived fields.
- Modify `$project` stages to include/exclude columns.

For example, to add a new calculated field like `transaction_value`:

```js
{ $set: { transaction_value: { $multiply: ["$amount", "$price"] } } }
```

Then re-run the playbook to redeploy updated processors.

---

## ğŸ§¹ Cleanup

To delete all processors and connections created by this demo:

```bash
ansible-playbook delete_processors.yml -e @processor_details_local.yml
```

---

## ğŸª¶ License

MIT License Â© 2025 Michael Ford
